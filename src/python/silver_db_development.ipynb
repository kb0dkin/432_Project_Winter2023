{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will connect to a postgres database using the public IP address of the VM\n",
    "# The bronze tables to create the silver tables\n",
    "\n",
    "import os \n",
    "import sqlalchemy\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point, Polygon\n",
    "import datetime\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## taxi_covid\n",
    "\n",
    "information about the destinations of taxis, mapped to the destination zip code with information about the weekly covid rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "user = 'postgres'\n",
    "password = '432'\n",
    "ip = '34.134.248.227'\n",
    "port = '5432'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zip(lat, long):\n",
    "    '''\n",
    "    Gets the zip code comparing the latitude and longitude to the zips.geojson file\n",
    "    \n",
    "    '''\n",
    "    point = Point(long, lat)\n",
    "    for i in range(len(zips)):\n",
    "        if point.within(zips['geometry'][i]):\n",
    "            return zips['zip'][i]\n",
    "        else:\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to database\n",
    "db_name = 'bronze'\n",
    "engine = sqlalchemy.create_engine(f\"postgresql+psycopg2://{user}:{password}@{ip}/{db_name}\")\n",
    "\n",
    "# select latitude and longitude from the table and run\n",
    "sql = \"SELECT trip_start_timestamp as ride_date, dropoff_centroid_latitude as lat, dropoff_centroid_longitude as long, trip_id FROM taxi_trips;\"\n",
    "df_taxi = pd.read_sql(sql, engine)\n",
    "sql = \"SELECT trip_start_timestamp as ride_date, dropoff_centroid_latitude as lat, dropoff_centroid_longitude as long, trip_id  FROM tnp_trips;\"\n",
    "df_tnp = pd.read_sql(sql,engine)\n",
    "\n",
    "# load zips.geojson file with geopandas\n",
    "zips = gpd.read_file('zips.geojson')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes the latitude and longitude from df and create a zip code column\n",
    "# Uses reverse_geocoder to find the zip code for each latitude and longitude using the zips.geojson file\n",
    "\n",
    "zip_list = [get_zip(lat_long[1]['lat'],lat_long[1]['long']) for lat_long in df_taxi[['long','lat']].iterrows()]\n",
    "df_taxi['zip'] = zip_list\n",
    "df_taxi['ride_type'] = 'taxi'\n",
    "\n",
    "zip_list = [get_zip(lat_long[1]['lat'],lat_long[1]['long']) for lat_long in df_tnp[['long','lat']].iterrows()]\n",
    "df_tnp['zip'] = zip_list\n",
    "df_tnp['ride_type'] = 'rideshare'\n",
    "\n",
    "# append the datasets\n",
    "df_ride = df_taxi.append(df_tnp, ignore_index=True, sort='ride_date')\n",
    "\n",
    "# get the week number, so we can join on the weekly covid info\n",
    "df_ride['week_number'] = [int(item.strftime(\"%W\")) for item in df_ride['ride_date']]\n",
    "df_ride['year'] = [item.strftime('%Y') for item in df_ride['ride_date']]\n",
    "\n",
    "# df.to_csv('./src/python/df.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now for the covid data\n",
    "sql_query = '''SELECT zip_code as zip, week_number, cases_weekly, week_start,\n",
    "                case_rate_cumulative, deaths_weekly, death_rate_weekly \n",
    "                from covid_19_zip;'''\n",
    "df_covid_zip = pd.read_sql(sql_query, conn)\n",
    "df_covid_zip.rename(columns={'cases_weekly':'covid_rate'}, inplace=True)\n",
    "df_covid_zip.rename(columns={'death_rate_weekly':'death_rate'}, inplace=True)\n",
    "\n",
    "\n",
    "df_covid_zip['year'] = [item.strftime('%Y') for item in df_covid_zip['week_start']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and to join on the zip and week_number\n",
    "df_taxi_covid = pd.merge(df_ride, df_covid_zip, how= 'left', on=['year','week_number','zip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close out the bronze connection\n",
    "# insert into the silver database :)\n",
    "user = 'postgres'\n",
    "password = '432'\n",
    "ip = '34.134.248.227'\n",
    "db_name = 'silver'\n",
    "port = '5432'\n",
    "\n",
    "# conn = psycopg2.connect(f'host={ip} dbname={db_name} user={user} password={password} port={port}')\n",
    "engine = sqlalchemy.create_engine(f\"postgresql+psycopg2://{user}:{password}@{ip}/{db_name}\")\n",
    "\n",
    "num_inserts = df_taxi_covid[['ride_type','ride_date','zip','covid_rate','trip_id','death_rate']].\\\n",
    "    to_sql(name = 'taxi_covid', con=engine, if_exists='append', index=False, chunksize=1000)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## midway_taxi_covid\n",
    "\n",
    "mostly the same as above, but looking to see if the destination is midway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None to midway, None to ohare\n"
     ]
    }
   ],
   "source": [
    "midway_zip = get_zip(41.786, -87.7525)\n",
    "ohare_zip = get_zip(41.978611,-87.904722)\n",
    "\n",
    "mdw_rows = df_taxi_covid['zip'].eq(midway_zip)\n",
    "midway_taxi_covid = df_taxi_covid.loc[mdw_rows,['ride_date','ride_type','zip','covid_rate']]\n",
    "\n",
    "ohare_rows = df_taxi_covid['zip'].eq(ohare_zip)\n",
    "ohare_taxi_covid = df_taxi_covid.loc[ohare_rows,['ride_date','ride_type','zip','covid_rate']]\n",
    "\n",
    "mdw_inserts = midway_taxi_covid.to_sql('midway_taxi_covid', con=engine,\\\n",
    "                                       if_exists='append', index=False, chunksize=1000)\n",
    "ord_inserts = ohare_taxi_covid.to_sql('ohare_taxi_covid', con=engine,\\\n",
    "                                      if_exists='append', index=False, chunksize=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'postgres'\n",
    "password = '432'\n",
    "ip = '34.134.248.227'\n",
    "db_name = 'silver'\n",
    "port = '5432'\n",
    "engine = sqlalchemy.create_engine(f\"postgresql+psycopg2://{user}:{password}@{ip}/{db_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MSDS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will connect to a postgres database using the public IP address of the VM\n",
    "# The bronze tables to create the silver tables\n",
    "\n",
    "import os \n",
    "import sqlalchemy\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point, Polygon\n",
    "import datetime\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'postgres'\n",
    "password = '432'\n",
    "ip = '34.134.248.227'\n",
    "port = '5432'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## taxi_covid\n",
    "\n",
    "information about the destinations of taxis, mapped to the destination zip code with information about the weekly covid rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zip(lat, long):\n",
    "    '''\n",
    "    Gets the zip code comparing the latitude and longitude to the zips.geojson file\n",
    "    \n",
    "    '''\n",
    "    point = Point(long, lat)\n",
    "    for i in range(len(zips)):\n",
    "        if point.within(zips['geometry'][i]):\n",
    "            return zips['zip'][i]\n",
    "        else:\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to database\n",
    "db_name = 'bronze'\n",
    "engine = sqlalchemy.create_engine(f\"postgresql+psycopg2://{user}:{password}@{ip}/{db_name}\")\n",
    "\n",
    "# select latitude and longitude from the table and run\n",
    "sql = \"SELECT trip_start_timestamp as ride_date, dropoff_centroid_latitude as lat, dropoff_centroid_longitude as long, trip_id FROM taxi_trips;\"\n",
    "df_taxi = pd.read_sql(sql, engine)\n",
    "sql = \"SELECT trip_start_timestamp as ride_date, dropoff_centroid_latitude as lat, dropoff_centroid_longitude as long, trip_id  FROM tnp_trips;\"\n",
    "df_tnp = pd.read_sql(sql,engine)\n",
    "\n",
    "# load zips.geojson file with geopandas\n",
    "zips = gpd.read_file('zips.geojson')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes the latitude and longitude from df and create a zip code column\n",
    "# Uses reverse_geocoder to find the zip code for each latitude and longitude using the zips.geojson file\n",
    "\n",
    "zip_list = [get_zip(lat_long[1]['lat'],lat_long[1]['long']) for lat_long in df_taxi[['long','lat']].iterrows()]\n",
    "df_taxi['zip'] = zip_list\n",
    "df_taxi['ride_type'] = 'taxi'\n",
    "\n",
    "zip_list = [get_zip(lat_long[1]['lat'],lat_long[1]['long']) for lat_long in df_tnp[['long','lat']].iterrows()]\n",
    "df_tnp['zip'] = zip_list\n",
    "df_tnp['ride_type'] = 'rideshare'\n",
    "\n",
    "# append the datasets\n",
    "df_ride = df_taxi.append(df_tnp, ignore_index=True, sort='ride_date')\n",
    "\n",
    "# get the week number, so we can join on the weekly covid info\n",
    "df_ride['week_number'] = [int(item.strftime(\"%W\")) for item in df_ride['ride_date']]\n",
    "df_ride['year'] = [item.strftime('%Y') for item in df_ride['ride_date']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now for the covid data\n",
    "sql_query = '''SELECT zip_code as zip, week_number, cases_weekly, week_start,\n",
    "                case_rate_cumulative, deaths_weekly, death_rate_weekly \n",
    "                from covid_19_zip;'''\n",
    "df_covid_zip = pd.read_sql(sql_query, conn)\n",
    "df_covid_zip.rename(columns={'cases_weekly':'covid_rate'}, inplace=True)\n",
    "df_covid_zip.rename(columns={'death_rate_weekly':'death_rate'}, inplace=True)\n",
    "\n",
    "\n",
    "df_covid_zip['year'] = [item.strftime('%Y') for item in df_covid_zip['week_start']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and to join on the zip and week_number\n",
    "df_taxi_covid = pd.merge(df_ride, df_covid_zip, how= 'left', on=['year','week_number','zip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# insert into the silver database :)\n",
    "db_name = 'silver'\n",
    "engine = sqlalchemy.create_engine(f\"postgresql+psycopg2://{user}:{password}@{ip}/{db_name}\")\n",
    "\n",
    "num_inserts = df_taxi_covid[['ride_type','ride_date','zip','covid_rate','trip_id','death_rate']].\\\n",
    "    to_sql(name = 'taxi_covid', con=engine, if_exists='append', index=False, chunksize=1000)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## midway_taxi_covid\n",
    "\n",
    "mostly the same as above, but looking to see if the destination is midway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'bronze'\n",
    "engine = sqlalchemy.create_engine(f\"postgresql+psycopg2://{user}:{password}@{ip}/{db_name}\")\n",
    "\n",
    "# select latitude and longitude from the table and run\n",
    "sql = \"SELECT trip_start_timestamp as ride_date, dropoff_centroid_latitude as lat, dropoff_centroid_longitude as long, trip_id FROM taxi_trips;\"\n",
    "df_taxi = pd.read_sql(sql, engine)\n",
    "sql = \"SELECT trip_start_timestamp as ride_date, dropoff_centroid_latitude as lat, dropoff_centroid_longitude as long, trip_id  FROM tnp_trips;\"\n",
    "df_tnp = pd.read_sql(sql,engine)\n",
    "\n",
    "# load zips.geojson file with geopandas\n",
    "zips = gpd.read_file('zips.geojson')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midway_zip = get_zip(41.786, -87.7525)\n",
    "ohare_zip = get_zip(41.978611,-87.904722)\n",
    "\n",
    "mdw_rows = df_taxi_covid['zip'].eq(midway_zip)\n",
    "midway_taxi_covid = df_taxi_covid.loc[mdw_rows,['ride_date','ride_type','zip','covid_rate']]\n",
    "\n",
    "ohare_rows = df_taxi_covid['zip'].eq(ohare_zip)\n",
    "ohare_taxi_covid = df_taxi_covid.loc[ohare_rows,['ride_date','ride_type','zip','covid_rate']]\n",
    "\n",
    "mdw_inserts = midway_taxi_covid.to_sql('midway_taxi_covid', con=engine,\\\n",
    "                                       if_exists='append', index=False, chunksize=1000)\n",
    "ord_inserts = ohare_taxi_covid.to_sql('ohare_taxi_covid', con=engine,\\\n",
    "                                      if_exists='append', index=False, chunksize=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'postgres'\n",
    "password = '432'\n",
    "ip = '34.134.248.227'\n",
    "db_name = 'silver'\n",
    "port = '5432'\n",
    "engine = sqlalchemy.create_engine(f\"postgresql+psycopg2://{user}:{password}@{ip}/{db_name}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permit_neighborhood and zip\n",
    "\n",
    "Put together the tables for building permits by neighborhood and zip, with information about health metrics\n",
    "\n",
    "__Zip__\n",
    "* permit_id\n",
    "* zip\n",
    "* unemployment\n",
    "* poverty\n",
    "* income\n",
    "\n",
    "\n",
    "__Neighborhood__\n",
    "* permit_id\n",
    "* neighborhood\n",
    "* unemployment\n",
    "* poverty\n",
    "* income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'bronze'\n",
    "engine = sqlalchemy.create_engine(f\"postgresql+psycopg2://{user}:{password}@{ip}/{db_name}\")\n",
    "# select latitude and longitude from the table and run\n",
    "sql = \"\"\"SELECT community_area, community_area_name, below_poverty_level as poverty,\n",
    "            per_capita_income as income, unemployment FROM health_ind;\"\"\"\n",
    "df_health_ind = pd.read_sql(sql, engine)\n",
    "sql = \"SELECT community_area, permit_ as permit_id, latitude, longitude from build_permit;\"\n",
    "df_permit = pd.read_sql(sql,engine)\n",
    "\n",
    "# load zips.geojson file with geopandas\n",
    "zips = gpd.read_file('zips.geojson')\n",
    "\n",
    "df_permit['zip'] = [get_zip(row.latitude, row.longitude) for i_row,row in df_permit.iterrows()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_permit_CA_zip = df_health_ind.merge(df_permit[['community_area','permit_id','zip']], how='left', on='community_area')\n",
    "df_permit_CA = df_permit_CA_zip.drop(columns=['community_area','zip'])\n",
    "df_permit_CA.rename(columns={'community_area_name':'neighborhood'}, inplace=True)\n",
    "df_permit_zip = df_permit_CA_zip.drop(columns=['community_area','community_area_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'silver'\n",
    "engine = sqlalchemy.create_engine(f\"postgresql+psycopg2://{user}:{password}@{ip}/{db_name}\")\n",
    "df_permit_CA.to_sql('permit_neighborhood',con=engine, if_exists='append', chunksize=1000, index=False)\n",
    "df_permit_zip.to_sql('permit_zip',con=engine, if_exists='append', chunksize=1000, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MSDS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
